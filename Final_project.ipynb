{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#validation using kfold\n",
    "from sklearn.cross_validation import KFold\n",
    "# Feature Scaling helps make computations easy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#splitting features \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. \n",
    "#installed using following command : conda install -c conda-forge xgboost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keras for deep learning\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Cabin' 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Dictionary\n",
    "\n",
    "#VariableDefinitionKey survival Survival 0 = No, 1 = Yes pclass Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd sex Sex Age Age in years sibsp # of siblings / spouses aboard the Titanic parch # of parents / children aboard the Titanic ticket Ticket number fare Passenger fare cabin Cabin number embarked Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "#Variable Notes\n",
    "\n",
    "#pclass: A proxy for socio-economic status (SES)\n",
    "#1st = Upper\n",
    "#2nd = Middle\n",
    "#3rd = Lower\n",
    "\n",
    "#age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "#sibsp: The dataset defines family relations in this way...\n",
    "#Sibling = brother, sister, stepbrother, stepsister\n",
    "#Spouse = husband, wife (mistresses and fianc√©s were ignored)\n",
    "\n",
    "#parch: The dataset defines family relations in this way...\n",
    "#Parent = mother, father\n",
    "#Child = daughter, son, stepdaughter, stepson\n",
    "#Some children travelled only with a nanny, therefore parch=0 for them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#categorical values \n",
    "#Categorical: Survived, Sex and Embarked. \n",
    "#Ordinal: Pclass.\n",
    "\n",
    "#numerical values\n",
    "#Continous: Age, Fare. \n",
    "#Discrete: SibSp, Parch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.apply(lambda x: sum(x.isnull()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.apply(lambda x: sum(x.isnull()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#As per the analysis done using sql and above description he following can be analyzed\n",
    "#Total samples are 891 or 40% of the actual number of passengers on board the Titanic (2,224).\n",
    "#Survived is a categorical feature with 0 or 1 values.\n",
    "#Around 38% samples survived representative of the actual survival rate at 32%.\n",
    "#Most passengers (> 75%) did not travel with parents or children.\n",
    "#Nearly 30% of the passengers had siblings and/or spouse aboard.\n",
    "#Fares varied significantly with few passengers (<1%) paying as high as $512.\n",
    "#Few elderly passengers (<1%) within age range 65-80.\n",
    "#Names are unique across the dataset (count=unique=891)\n",
    "#Sex variable as two possible values with 65% male (top=male, freq=577/count=891).\n",
    "#Cabin values have several dupicates across samples. Alternatively several passengers shared a cabin.\n",
    "#Embarked takes three possible values. S port used by most passengers (top=S)\n",
    "#Ticket feature has high ratio (22%) of duplicate values (unique=681)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Brown, Mrs. Thomas William Solomon (Elizabeth ...</td>\n",
       "      <td>male</td>\n",
       "      <td>1601</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Name   Sex Ticket  \\\n",
       "count                                                 891   891    891   \n",
       "unique                                                891     2    681   \n",
       "top     Brown, Mrs. Thomas William Solomon (Elizabeth ...  male   1601   \n",
       "freq                                                    1   577      7   \n",
       "\n",
       "              Cabin Embarked  \n",
       "count           204      889  \n",
       "unique          147        3  \n",
       "top     C23 C25 C27        S  \n",
       "freq              4      644  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.242363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived\n",
       "0       1  0.629630\n",
       "1       2  0.472826\n",
       "2       3  0.242363"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pclass : significant correlation (>0.5) among Pclass=1 and Survived.  use this feature in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Survived\n",
       "0  female  0.742038\n",
       "1    male  0.188908"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sex :females have high survival rate at 74%. As seen in the movie women and children were rescued first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.535885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.464286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.345395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SibSp  Survived\n",
       "1      1  0.535885\n",
       "2      2  0.464286\n",
       "0      0  0.345395\n",
       "3      3  0.250000\n",
       "4      4  0.166667\n",
       "5      5  0.000000\n",
       "6      8  0.000000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sibsp : no relevant correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parch</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.550847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.343658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parch  Survived\n",
       "3      3  0.600000\n",
       "1      1  0.550847\n",
       "2      2  0.500000\n",
       "0      0  0.343658\n",
       "5      5  0.200000\n",
       "4      4  0.000000\n",
       "6      6  0.000000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parch : no relevant correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x12742cda0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADQCAYAAABStPXYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0v8BBmEn9XSaP90AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1274455c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = sns.FacetGrid(train_df, col='Survived')\n",
    "graph.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Most passengers are in 15-35 age range.\n",
    "#Many passegers who were 15-25 years old did not survive.\n",
    "#passengers less than 5 years of age had high chances of survival\n",
    "#80year old passenger survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAKACAYAAADwwl1dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1274d5ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = sns.FacetGrid(train_df, col='Survived', row='Pclass')\n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=10)\n",
    "grid.add_legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pclass=3 mostly did not survive and Most passengers in Pclass=1 survived. Hence we assume that upper class passengers have more chancs of survival.\n",
    "#Infant passengers mostly survived  except in for Pclass =2 or 3.  we can assume that infants have more chances of survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1279c66d8>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAKACAYAAABkCDbqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127b64e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = sns.FacetGrid(train_df, row='Embarked')\n",
    "grid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#as mentioned earlier females have a higher chance of survival except for Embarked=q. \n",
    "#we can assume embarked is related to pclass or cabin which is related to survival. no direct correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x127ff3b00>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAKACAYAAAAb9eZeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X2YXWV97//3kEmwAwNGGVSQCvjwRdFCQa2CgVCDGkUB\n9cipKFAVWxrUclQKnnCKj7QK8ZRWxEPFgBS0Uml9aAQFwwlwISJQHvNFfyJ6UEuERAJRIGZ+f6w1\nZTNMZtY8rJnMvd+v68qVvfda676/e82+92c97b17BgcHkSSpBFvNdAGSJE0VQ02SVAxDTZJUDENN\nklQMQ02SVAxDTZJUjN6ZLmCmRMSuwJ3A7cMmnZOZn2nYxkrg1MxcOcEalgMrM3P5BJY9BliYmcdM\nYNke4FTgcGAQeBj4X5n5rRHm/Ulm7jrC428GTqZ6DW0FnJ+ZnxpvLSO0++cAmXn2JNtZyQT/NhHx\n+8AFwI5AAkdm5oOTqWe2cFw4Lhq08RFgU2aeOpla2tK1oVb7eWbuPdNFzIC3APsC+2Tmxoh4HnB1\nROyZmfeOtXBE7AycUS9/X0RsC1wZEZmZX5tMYZMdtFPkLOCszPxSRJwCnAL81QzXNJ0cF46LJ4iI\n7YFlwJ8An5zhcjar20NtsyLil8DXgQXAL6je6N4LPBM4JjOvrGd9d0QsA3qAEzJzZf3i/jzwZOAZ\nwEWZeVK9FXk0sEPd9lBffcBl9XyfiYijgL+k2tL7AbAkM38bEW8HlgIPAHcDj9t7iIg59fzDHZGZ\n2XH/6cAcYGtgY2beWW9hPtpw9ewAzAX6gPsy88GIOBr4bV3HT6i2ln8SEQuptgwX1luJ9wN7Av8E\n7JiZx9fLnA78HNiu7uN+4HkjTP8/wGeAF9bP4W8z86KI2Br4R+DFwE/qGh8nIg4H/nrYw5mZR3TM\nMxc4ADisfmg5cCXdFWqb5bgYVbHjonYo8EOq4N5idXuo7RQRNw177O2ZeQvwNOAbmXlsRHwXODwz\nF9Qv0r+keqMDeDAz94mIPwC+GRHPodqSuSgzz6u3bn5Wv/igGvzPr7cElwPzgK8CF9cDd0/gWGC/\nesCeBnwgIs6l2jraG7gP+CbDBm9m/q6ePpbzqbZK10TEKuAK4LzMXNtkpWXmf0TEvwE/jogbge8C\nF2bmjxosfnNmvjEidgRuiIj3AZuANwMvB/6snu9Lm5m+FPhBZh4dEdsB10TE94A31rU9PyKeC9w8\nQt2XAJeMUd8OwAOZubG+/wuqv1k3cVw4LkZ6fucDRMSpDZ7PjOn2UBvrMMuK+v+7gas6bs/vmOfz\nAJl5c0SsAfbIzNMj4qCI+ADVltM8YJt6/hs63jABPkr14nxjff8g4LnAtRFBvewNwH7ANZn5nwAR\ncQHwys5im26R1oN0/4h4EXAw8HrgxIh4SWb+eJT18V8y87iI+BjwKuDVdb1HZuZXx1j0e/Xy99Zv\nnAcBjwB3ZuYv6uc82vRFQF9EvKNubxuqLdyFwOfqZX8YEdcM77jhFmnPCDVvGuM5lcZx4bgYaU9t\nVuj2UBtVZj7ScXfjZmbrfLwHeDQizgB2By4E/hVYxGNvlr8ZtvxFwLbAh4EPUh06+OfMfC9AfVy+\nl2qgdl6t+oR6mm6RRsT/AC7PzP8AbgGWRcQ/AW8CxjypHRGvA7bNzC8DXwC+EBHHAu+k2roe7Hi+\nc4ct3vn8LwCOoBqcF4zQ1UjT5wBvy8wb6lqeRnVI5t2MvX6abJGuAbaLiDn1+nwG1eEd1RwXm12+\n5HExa3hJ/+QdCRARL6Y67v1Dqq28T2XmV4BdgJ2pXnQjuQk4EXhbROwNrAQOj4gdo7oa67NUh3Wu\nAl4WETtHxFZUL+qJ2h74aP3GMHTuYre6liY2AKdFdaXc0FVjLwBurKf/imorEarj8Jvzb1Tnr15N\nNeibTL8COK7u9xlUh1N+H/gO8NaI2CoinkW1BT9umfkosIrH1u9RPLZnouYcFwWNi9mk20Ntp4i4\nadi/M8fZxrb18fOzgbfWb4qnAV+MiB9QbWVeTzU4RpSZ9wMnAecAt1JtnV4B3Eb1N/qb+vDKe6he\npNdRnRSfqI8CdwA3R8TtdXvnZ+a3myycmd+ta/xGRCSwmurN6SP1LH8N/F1EfB9YN0o7vwGuBq7L\nES6Z38z0DwO/FxG3Uq2jEzPz/6O6YOGB+nkNrceJ+guqCx1up7ogYukk2pqNHBeOi1mrx5+e0Whi\nM5/HkbqZ42LL1e17apKkgrinJkkqhntqkqRiGGqSpGJs0Z9TW7NmvcdG1RUGBvpH+tD3iBwX6gbj\nGROd3FOTJBXDUJMkFcNQkyQVw1CTJBXDUJMkFcNQkyQVw1CTJBXDUJMkFcNQkyQVw1CTJBXDUJMk\nFcNQkyQVo7UvNI6IucB5wK7A74BjgY3AcmCQ6mfFl2TmprZqkCR1lzb31F4L9GbmfsBHgI8Dy4Cl\nmbkA6AEObbF/SVKXaTPU7gR6I2IrYDvgUWBf4Mp6+gpgUYv9S5K6TJu/p/Yg1aHH1cAOwCHAAZk5\n9FtQ64HtR2tg/vw+envntFiiNPs4LqTNazPUTgAuzcyTI2IX4ApgXsf0fmDdaA2sXbuhxfKkLcfA\nQH/jeR0X6gbjGROd2jz8uBb4dX37fmAucGNELKwfWwysarF/SVKXaXNP7dPAuRGximoP7UPA9cA5\nETEPuAO4uMX+JUldpmdwcHDsuWbImjXrt9zipCk0MNDf03Rex4W6wXjGRCc/fC1JKoahJkkqhqEm\nSSqGoSZJKoahJkkqhqEmSSqGoSZJKoahJkkqhqEmSSqGoSZJKoahJkkqhqEmSSqGoSZJKoahJkkq\nhqEmSSqGoSZJKoahJkkqhqEmSSqGoSZJKoahJkkqhqEmSSqGoSZJKoahJkkqhqEmSSqGoSZJKoah\nJkkqhqEmSSqGoSZJKoahJkkqhqEmSSqGoSZJKoahJkkqRm+bjUfEycAbgHnAWcCVwHJgELgVWJKZ\nm9qsQZLUPVrbU4uIhcB+wP7AgcAuwDJgaWYuAHqAQ9vqX5LUfdrcU3s1cAtwCbAd8EHgWKq9NYAV\nwKvq6SOaP7+P3t45LZYozT6OC2nz2gy1HYBnAYcAuwFfA7bKzMF6+npg+9EaWLt2Q4vlSVuOgYH+\nxvM6LtQNxjMmOrUZavcBqzPzESAj4rdUhyCH9APrWuxfktRl2rz68SrgNRHRExE7AdsAl9fn2gAW\nA6ta7F+S1GVa21PLzG9ExAHAdVThuQS4CzgnIuYBdwAXt9W/JKn79AwODo491wxZs2b9llucNIUG\nBvp7ms7ruFA3GM+Y6OSHryVJxTDUJEnFMNQkScUw1CRJxTDUJEnFMNQkScUw1CRJxTDUJEnFMNQk\nScUw1CRJxTDUJEnFMNQkScUw1CRJxTDUJEnFMNQkScUw1CRJxTDUJEnFGFeoRcT8tgqRJGmyepvM\nFBF7A18C+iLi5cCVwFsy84Y2i5MkaTya7qmdCRwO3JeZ9wDHAWe3VpUkSRPQNNT6MvOOoTuZ+W1g\n63ZKkiRpYpqG2v0RsRcwCBARRwL3t1aVJEkT0OicGtXhxvOAPSNiHfBD4MjWqpIkaQKahtrBmfmK\niNgGmJOZD7RZlCRJE9E01I4Hzs7Mh9osRpKkyWgaaj+LiCuA7wG/GXowMz/SSlWSJmXF1atnuoRZ\nY/H+e8x0CZpCTUPt2o7bPW0UIknSZDUKtcz8cOf9iOgBdmulIkmSJqjpN4ocD3wC2Kbj4buA57RR\nlCRJE9H0c2rvB/YCvgw8G3gn1fk1SZK2GE1D7d7MvAu4GXhRZi4HorWqJEmagKYXijwUEQdRhdph\nEfF9YMxv7I+IHYEfAAcDG4HlVN9KciuwJDM3TaRoSZJGMuqeWkTsXN98D/B64FvAU4HVwN+Psexc\n4HM89hGAZcDSzFxAdQXloRMvW5KkJxprT+3rwD6ZeVtE3FPvWb2pYdunU32T/8n1/X2pfrIGYAXw\nKuCScdYrSdJmjRVqnZ9JOxI4o0mjEXEMsCYzL42IoVDryczB+vZ6YPux2pk/v4/e3jlNupS6RpNx\n0dfnj2g0NTDQP9MlaAqNFWqDHbfH86HrdwCDEbEI2Bs4H9ixY3o/sG6sRtau3TCOLqXZazxvrE3G\nxYYND0+mnK6yZs36mS5BI5joxkbTqx/h8QE3qsw8IDMPzMyFwE3AUcCKiFhYz7IYWDWOviVJGtNY\ne2p7RsSP69s7d9zuAQYzc/dx9PV+4JyImAfcAVw8vlIlSRrdWKH2vMl2UO+tDTlwsu1JkrQ5o4Za\nZt49XYVIkjRZ4zmnJknSFs1QkyQVw1CTJBXDUJMkFcNQkyQVw1CTJBXDUJMkFcNQkyQVw1CTJBXD\nUJMkFcNQkyQVw1CTJBXDUJMkFWOsn56RJDWw4urVM13CrLF4/z1aa9s9NUlSMQw1SVIxDDVJUjEM\nNUlSMQw1SVIxDDVJUjEMNUlSMQw1SVIx/PC1JsQPmjbX5gdNJT2ee2qSpGIYapKkYhhqkqRiGGqS\npGIYapKkYhhqkqRiGGqSpGIYapKkYrTy4euImAucC+wKbA18DLgdWA4MArcCSzJzUxv9S5K6U1t7\nam8D7svMBcBrgH8AlgFL68d6gENb6luS1KXaCrWvAKfUt3uAjcC+wJX1YyuARS31LUnqUq0cfszM\nBwEioh+4GFgKnJ6Zg/Us64Htx2pn/vw+envnjNnfxZfdPPFiu8ibX/UHU9ZWX9/WU9ZW6QYG+qe0\nvSbjwr9Pc1P193GdNzfVY6JTa19oHBG7AJcAZ2XmhRHxyY7J/cC6sdpYu3ZDo742bHh4QjV2mzVr\n1k9ZW67z5pqs9/EM8ibjwr9Pc1M1LlznzU31mOjUyuHHiHgacBnwV5l5bv3wjRGxsL69GFjVRt+S\npO7V1p7ah4D5wCkRMXRu7X3AmRExD7iD6rCkJElTpq1zau+jCrHhDmyjP0mSwA9fS5IKYqhJkoph\nqEmSimGoSZKKYahJkophqEmSimGoSZKKYahJkophqEmSimGoSZKKYahJkophqEmSimGoSZKKYahJ\nkophqEmSimGoSZKKYahJkophqEmSimGoSZKKYahJkophqEmSimGoSZKKYahJkophqEmSimGoSZKK\nYahJkophqEmSimGoSZKKYahJkophqEmSimGoSZKKYahJkorRO52dRcRWwFnAXsDDwLsy80fTWYMk\nqVzTvad2GPCkzHw5cBJwxjT3L0kqWM/g4OC0dRYRy4DrMvNL9f17MnPnaStAklS06d5T2w74dcf9\n30XEtB4ClSSVa7pD7QGgv7P/zNw4zTVIkgo13aF2NfBagIh4GXDLNPcvSSrYdB/6uwQ4OCKuAXqA\nP53m/iVJBZvWC0UkSWqTH76WJBXDUJMkFcNQkyQVw1CTJBXDUJMkFcNQkyQVw1CTJBXDUJMkFcNQ\nkyQVw1CTJBXDUJMkFaNrf8ssInYF7gRuHzbpnMz8TMM2VgKnZubKCdawHFiZmcsnsOwxwMLMPGaC\nfQfwKWC3+qFbgPdm5q+GzbcQOGZ4PxGxNbAMOBDYBKwD3p+Z359IPcPa/nfgXZn580m0sSvVut11\ngsu/FVgKzAM+3fQ1MZs5JhwTDdrYDrgGOCQzfzLRdtrUtaFW+3lm7j3TRUy3iNgJ+C7wZ5n59Yjo\nAU6m+hWFBQ2b+UuqPf0XZeZgROwPfC0ifj8zH51MfZn52sksP1kRsTPwcWBf4GHgmoj4bmYOf7Mv\nkWPCMTGiiPgj4BzgeTNdy2i6PdQ2KyJ+CXyd6gX9C+As4L3AM6m20q6sZ313RCyj+imdEzJzZf2m\n+HngycAzgIsy86R6S/JoYIe67aG++oDL6vk+ExFH8dgA+QGwJDN/GxFvp9p7eAC4G3hwWM1z6vmH\nOyIzs+P+ccBlmfl1gHoA/i1wV0T0Nvzh1qdT7cXMBR7JzKsj4k+BOfVgPjUzF9Z1LQdW1v++BfwK\n+C3wFODdmXl9XfvdwD7AdcBC4Kubmf4s4NNAX93Wn2XmXRHxh1TrHeA/Rio6Ir4A/OGwhz+Vmf/U\ncX8RcEVm3l8vczHwZuAjDdZLsRwTYyp5TAAcCywBvthgXcyYbg+1nSLipmGPvT0zbwGeBnwjM4+N\niO8Ch2fmgog4mmpwDQ3gBzNzn4j4A+CbEfEc4E+oBuN5EbE98LOIOL2e/5nA8zNzY/3Cnkf1Qr24\nHrx7Ur149qsH7WnAByLiXOCTwN7AfcA3GTaAM/N39fSx/GG9/PBlL2qw7JC/q9tYUx9yuhw4r655\ntOUCeE1m/iQiTgD+O3A98MfAzZl5b8fyXxw+neqQzreB12fmTyPi1VRbj4uA86neRL8TEacABw3v\nPDOb/IbfTlRv2kN+Aby0wXIlcEw8flnHxGPzvQtgjOcy47o91MY61LKi/v9u4KqO2/M75vk8QGbe\nHBFrgD0y8/SIOCgiPgC8kGqQblPPf8Owrb6PUh1/f2N9/yDgucC19YtnHnADsB9wTWb+J0BEXAC8\nsrPYcWyVbqLaip6wegC+EHgJ1eA5Cjih3jIczb0dx+Ivojq090GqN70Lhs070vTnAc+mOqwzNN92\nEbEDsFNmfqd+bDnwzuGdN9wqHWndbBrjeZXCMTFBhY+JWaPbQ21UmflIx93NHX7ofLwHeDQizgB2\nBy4E/pXqBT40YH4zbPmLgG2BDwMfBOYA/5yZ7wWIiG2p/k6v5PFXqz6hnnFslV4PvLjzgYjYCrgY\nOG7oTWI0EfEJ4DOZeR3VoZFPRMTVwMHAvTz+DWJux+3/ev6Z+cuIuJPqsMoi4Phhz2ek6c8Ffjz0\nxlu/aT0NGBzW54h/r4Zbpffw+PMozwAmfIK+JI6JzSt8TMwaXtI/eUcCRMSLge2AH1K9iD+VmV8B\ndgF2phqYI7kJOBF4W0TsTXWM/fCI2LE+Wf1ZqkM7VwEvi4id68F2xCRq/j/A6yLitXXtPcApwI5N\nBm9tZ+CUiJhXt/EUYIDqirFfAbtHxJPqx0c70f5F4Ayqq7I2NJi+GnhKRAy1+Q7gwsy8D7g7Il5X\nP/7Whs9jJN8BXhkRA/W5nTdRnfdQM44JihsTs0a3h9pOEXHTsH9njrONbSPiRuBs4K31VU6nAV+M\niB9QbWlez2OXCT9BfUHCSVTHwW+l2kK9AriN6m/0N/XAeg/VG+51VCfGJyQzfwksBt4fEbfU/TwX\nOGwczRxf13ZnRNxGdf7gpMxcnZm3UZ1buA34CrBqlHYuqfsefphlxOmZ+TDw34AzIuJmqosMhg6p\nvA346/rv8exxPJfHycx7gP9JdTXcTVRvENdNtL1ZxjHhmJjVegYHB2e6Bm3BYjOfyZG6lWNiy9bt\ne2qSpIK4pyZJKoZ7apKkYhhqkqRiGGqSpGJs0R++XrNmvSf81BUGBvobf5uF40LdYDxjopN7apKk\nYhhqkqRiGGqSpGIYapKkYhhqkqRiGGqSpGIYapKkYmzRn1OTNDErrl490yXMGov332OmS9AUck9N\nklQMQ02SVAxDTZJUjNbOqUXEXOA8YFfgd8CxwEZgOTBI9RPtSzJzU1s1SJK6S5t7aq8FejNzP+Aj\nwMeBZcDSzFwA9ACHtti/JKnLtBlqdwK9EbEVsB3wKLAvcGU9fQWwqMX+JUldps1L+h+kOvS4GtgB\nOAQ4IDOHfjZjPbD9aA3Mn99Hb++cFkuUZp8m46Kvb+tpqmb2Gxjon+kSNIXaDLUTgEsz8+SI2AW4\nApjXMb0fWDdaA2vXbmixPGnLMZ431ibjYsOGhydTTldZs2b9TJegEUx0Y6PNw49rgV/Xt+8H5gI3\nRsTC+rHFwKoW+5ckdZk299Q+DZwbEauo9tA+BFwPnBMR84A7gItb7F+S1GVaC7XMfBB4ywiTDmyr\nT0lSd/PD15KkYhhqkqRiGGqSpGIYapKkYhhqkqRiGGqSpGIYapKkYhhqkqRiGGqSpGIYapKkYhhq\nkqRiGGqSpGK0+S39ktQ1Vly9eqZLmDUW779Ha227pyZJKoahJkkqhqEmSSqGoSZJKoahJkkqhqEm\nSSqGoSZJKoahJkkqhqEmSSqGoSZJKoahJkkqhqEmSSqGoSZJKoahJkkqhqEmSSqGoSZJKoahJkkq\nhqEmSSqGoSZJKkZvm41HxMnAG4B5wFnAlcByYBC4FViSmZvarEGS1D1a21OLiIXAfsD+wIHALsAy\nYGlmLgB6gEPb6l+S1H3a3FN7NXALcAmwHfBB4FiqvTWAFcCr6ukjmj+/j97eOS2WKM0+TcZFX9/W\n01TN7Dcw0D8l7bjOm5uqdT6SNkNtB+BZwCHAbsDXgK0yc7Cevh7YfrQG1q7d0GJ50pZjPIO8ybjY\nsOHhyZTTVdasWT8l7bjOm2uyzicafG2G2n3A6sx8BMiI+C3VIcgh/cC6FvuXJHWZNq9+vAp4TUT0\nRMROwDbA5fW5NoDFwKoW+5ckdZnW9tQy8xsRcQBwHVV4LgHuAs6JiHnAHcDFbfUvSeo+rV7Sn5kn\njvDwgW32KUnqXn74WpJUDENNklQMQ02SVAxDTZJUDENNklQMQ02SVAxDTZJUDENNklQMQ02SVAxD\nTZJUDENNklQMQ02SVAxDTZJUDENNklQMQ02SVAxDTZJUDENNklQMQ02SVIxxhVpEzG+rEEmSJqu3\nyUwRsTfwJaAvIl4OXAm8JTNvaLM4SZLGo+me2pnA4cB9mXkPcBxwdmtVSZI0AU1DrS8z7xi6k5nf\nBrZupyRJkiamaajdHxF7AYMAEXEkcH9rVUmSNAGNzqlRHW48D9gzItYBPwSObK0qSZImoGmoHZyZ\nr4iIbYA5mflAm0VJkjQRTUPteODszHyozWIkSZqMpqH2s4i4Avge8JuhBzPzI61UJUnSBDQNtWs7\nbve0UYgkSZPVKNQy88Od9yOiB9itlYokSZqgpt8ocjzwCWCbjofvAp7TRlGSJE1E08+pvR/YC/gy\n8GzgnVTn1yRJ2mI0Pad2b2beFRE3Ay/KzOX13tuoImJH4AfAwcBGYDnVB7hvBZZk5qaJlS1J0hM1\n3VN7KCIOAm4GXh8RTwdG/cb+iJgLfI7HrpZcBizNzAVUF5scOrGSJUka2aihFhE71zffA7we+Bbw\nVGA18PdjtH061Zce/7y+vy/Vt/sDrAAWTaBeSZI2a6zDj18H9snM2yLinvpw4ZvGajQijgHWZOal\nEXFy/XBPZg7Wt9cD24/Vzvz5ffT2zhlrNqmrNBkXfX1+33hTAwP9U9KO67y5qVrnIxkr1Do/k3Yk\ncEbDdt8BDEbEImBv4Hxgx47p/cC6sRpZu3ZDw+6k2W08g7zJuNiw4eHJlNNV1qxZPyXtuM6ba7LO\nJxp8Y51TG+y43fhD15l5QGYemJkLgZuAo4AVEbGwnmUxsGocdUqSNKamVz/C4wNuIt4PnBMR84A7\ngIsn2Z4kSY8zVqjtGRE/rm/v3HG7BxjMzN3H6qDeWxty4PhLHNuKq1e30WxxFu+/x0yXIEmtGivU\nnjctVUiSNAVGDbXMvHu6CpEkabKafvhakqQtnqEmSSqGoSZJKoahJkkqhqEmSSqGoSZJKoahJkkq\nhqEmSSqGoSZJKoahJkkqhqEmSSqGoSZJKoahJkkqhqEmSSqGoSZJKoahJkkqhqEmSSqGoSZJKoah\nJkkqhqEmSSqGoSZJKoahJkkqhqEmSSqGoSZJKoahJkkqhqEmSSqGoSZJKoahJkkqhqEmSSqGoSZJ\nKkZvG41GxFzgXGBXYGvgY8DtwHJgELgVWJKZm9roX5LUndraU3sbcF9mLgBeA/wDsAxYWj/WAxza\nUt+SpC7VVqh9BTilvt0DbAT2Ba6sH1sBLGqpb0lSl2rl8GNmPggQEf3AxcBS4PTMHKxnWQ9sP1Y7\n8+f30ds7Z8z++vq2nnixXWRgoH+mS9AUaDIuHBPNTdW4cJ031+Z7USuhBhARuwCXAGdl5oUR8cmO\nyf3AurHaWLt2Q6O+Nmx4eEI1dps1a9bPdAnajPEM8ibjwjHR3FSNC9d5c03W+USDr5XDjxHxNOAy\n4K8y89z64RsjYmF9ezGwqo2+JUndq609tQ8B84FTImLo3Nr7gDMjYh5wB9VhSUmSpkxb59TeRxVi\nwx3YRn+SJIEfvpYkFcRQkyQVo7WrH1W2FVevnukSZo3F++8x0yVIXcM9NUlSMQw1SVIxDDVJUjEM\nNUlSMQw1SVIxDDVJUjEMNUlSMQw1SVIxDDVJUjEMNUlSMQw1SVIxDDVJUjEMNUlSMQw1SVIxDDVJ\nUjEMNUlSMQw1SVIxDDVJUjEMNUlSMQw1SVIxDDVJUjEMNUlSMQw1SVIxDDVJUjEMNUlSMQw1SVIx\nDDVJUjEMNUlSMQw1SVIxeqezs4jYCjgL2At4GHhXZv5oOmuQJJVruvfUDgOelJkvB04Czpjm/iVJ\nBZvuUHsF8C2AzLwWePE09y9JKljP4ODgtHUWEf8I/Etmrqjv/xTYPTM3TlsRkqRiTfee2gNAf2f/\nBpokaapMd6hdDbwWICJeBtwyzf1Lkgo2rVc/ApcAB0fENUAP8KfT3L8kqWDTek5NkqQ2+eFrSVIx\nDDVJUjEMNUlSMQw1SVIxDDVJUjEMNUlSMQw1SVIxDDVJUjEMNUlSMQw1SVIxDDVJUjEMNUlSMab7\nW/q3GBGxK3AncPuwSedk5mcatrESODUzV06whuXAysxcPoFljwEWZuYxE+x7N+B04IXAo8Bq4AOZ\n+ZMR5l0JHDN8WkQsBE4D+qheS98ETs7M302kpo523wC8ODP/1yTbWc7E1++TgX8CdgfWAG/JzF9O\npp4tnWPCMdGwjXcAB0x0Pbeta0Ot9vPM3Humi5huEbEDcBXwwcx8U/3Y24CrImKvzLyvQRtbAxcC\n+2fmXRExD/gXYAlw5mTqy8yvAV+bTBtT4GPAqsx8XUS8Hfg74IgZrmk6OCYcEyOKiCcBp1I9n3+Z\nyVpG0+2htlkR8Uvg68AC4BfAWcB7gWdSbaFdWc/67ohYRvX7cCdk5sqI2Bn4PPBk4BnARZl5Ur0l\neTSwQ932UF99wGX1fJ+JiKOAv6Q6PPwDYElm/rZ+c11K9QvidwMPDqt5Tj3/cEdkZnbc/3Pg/2bm\nhUMPZOah0l09AAARIElEQVQF9dbgnwMfb7CK+oDtgW3q5R+JiPcB29a1rKTeYq/3AFZm5q71luJT\ngecAJwHHZuYh9TLHA88DbgAWAl8F3j3C9BOAT9XzzAGWZ+anI6IHOAM4BPh5PW3lsHX0R8Dnhj2X\n9Zm5YNhjrwMOqG9fBHwmIuZm5qMN1k2RHBNjKn1MHEC1/k8E/qjB+pgR3R5qO0XETcMee3tm3gI8\nDfhGZh4bEd8FDs/MBRFxNNXgGhrAD2bmPhHxB8A3I+I5wJ9QDcbzImJ74GcRcXo9/zOB52fmxvrF\nPI/qhXpxPXj3BI4F9qsH7WnAByLiXOCTwN7AfVSHNR43gOtDHE22sl8KfHeEx68EXt1geTJzbUR8\nArghIlbX7X0lM69qsPh9mfn6iJgLfDYi5mfmWqr1dgLwgnq+FcDZI0w/tq5hn3rr+NKIuJ7qb/aH\nwJ5Ub543j1D392i2jnaieuOm/ls9AAxQvTGUzDHxeI6Jx+a7DLis3hDZYnV7qI11qGVF/f/dVIcm\nhm7P75jn8wCZeXNErAH2yMzTI+KgiPgA1fH5edRbb8ANmbmxY/mPApuAN9b3DwKeC1wbEdTL3gDs\nB1yTmf8JEBEXAK/sLHYcW6Wb83tUW3KNZObHI+JzwMH1vxURcUpm/u8xFv1evfyjEfFV4E0R8W3g\nqZl5XUS8YIzpJwJ7R8Qf1+1tC7yIauB/td6bWhMR/z6843FslfaMUPemMZ5XCRwTj+eYmGW6PdRG\nlZmPdNzduJnZOh/vAR6NiDOoLjC4EPhXYBGPvUn+ZtjyF1G9AD8MfJBqAP1zZr4XICK2pfo7vZLH\nX636hHrGsVX6fToOH0TEjpl5L/Ay4PoGyxMRLwP2ycyz6udwUURcBPzv+t8gjz3nucMW71wHF1C9\nic2nWl/DjTR9DnBiZn61rmUH4CGqrfax1lHTPbV7gKcD/y8ieoHtqPYGuppjYvO6YEzMCl7SP3lH\nAkTEi6ne+H5ItYX2qcz8CrALsDOb39q7ieoY9dsiYm+q492HR8SO9fHwz1Id2rkKeFlE7BwRWzG5\nixY+C7wiIt5a3z87Ii4F9qc6T9LE/cCpEbFXx2N7AjfWt39V3wc4bHONZOa1VIf63k41WJtMvwI4\nNiLm1m9wV1G9IX0H+G8RsXVEzAde0/C5jOTfgaPq20dQXTTStefTxskx8ZiSxsSs0O17aiOdP/i/\nQ1uEDW0bETcCvwPeWh8eOA34YkSsA/6Taktvt801kJn3R8RJwDlUW4YfpnqRbkU1IP6mPpfwHqoX\n6UM88bLrxjLzVxFxAHBGRJxKtQW5uq71dcC5Ddq4sz62/vn6HMkmqkMox9ezfBI4L6rLf/91jOa+\nDLwmM3/ccPrZVIejbqR6DX8h60vII+IlwK3AL5nEOgJOAZZHxG3AOuo36i7gmHBMzGo9g4ODM12D\nthAR0Q+8NDMvH/b4Skb4TI5UOsfE7NPte2rqkJnrgcvHnFHqEo6J2cc9NUlSMbxQRJJUDENNklSM\nLfqc2po16z02qq4wMNA/0oe9R+S4UDcYz5jo5J6aJKkYhpokqRiGmiSpGIaaJKkYhpokqRiGmiSp\nGIaaJKkYhpokqRiGmiSpGIaaJKkYhpokqRitffdjRMwFzgN2pfoF3GOBjcByql+VvRVYkpmb2qpB\nktRd2txTey3Qm5n7AR8BPg4sA5Zm5gKgBzi0xf4lSV2mzVC7E+iNiK2A7YBHgX2BK+vpK4BFLfYv\nSeoybf70zINUhx5XAzsAhwAHZObQz2asB7YfrYH58/vo7Z3TYonS7OO4kDavzVA7Abg0M0+OiF2A\nK4B5HdP7gXWjNbB27YYWy5O2HAMD/Y3ndVyoG4xnTHRq8/DjWuDX9e37gbnAjRGxsH5sMbCqxf4l\nSV2mzT21TwPnRsQqqj20DwHXA+dExDzgDuDiFvuXJHWZnsHBLfeX4f3ZenWL8fx0veNC3WA8Y6KT\nH76WJBXDUJMkFcNQkyQVw1CTJBXDUJMkFcNQkyQVw1CTJBXDUJMkFcNQkyQVw1CTJBXDUJMkFcNQ\nkyQVw1CTJBXDUJMkFcNQkyQVw1CTJBXDUJMkFcNQkyQVw1CTJBXDUJMkFcNQkyQVw1CTJBXDUJMk\nFcNQkyQVw1CTJBXDUJMkFcNQkyQVw1CTJBXDUJMkFcNQkyQVw1CTJBXDUJMkFaO3zcYj4mTgDcA8\n4CzgSmA5MAjcCizJzE1t1iBJ6h6t7alFxEJgP2B/4EBgF2AZsDQzFwA9wKFt9S9J6j5tHn58NXAL\ncAnwdeAbwL5Ue2sAK4BFLfYvSeoybR5+3AF4FnAIsBvwNWCrzBysp68Hth+tgfnz++jtndNiidLs\n47iQNq/NULsPWJ2ZjwAZEb+lOgQ5pB9YN1oDa9duaLE8acsxMNDfeF7HhbrBeMZEpzYPP14FvCYi\neiJiJ2Ab4PL6XBvAYmBVi/1LkrpMa3tqmfmNiDgAuI4qPJcAdwHnRMQ84A7g4rb6lyR1n57BwcGx\n55oha9as33KLk6bQwEB/T9N5HRfqBuMZE5388LUkqRiGmiSpGIaaJKkYhpokqRiGmiSpGIaaJKkY\nhpokqRiGmiSpGIaaJKkYhpokqRiGmiSpGIaaJKkYhpokqRiGmiSpGIaaJKkYhpokqRiGmiSpGIaa\nJKkY4wq1iJjfViGSJE1Wb5OZImJv4EtAX0S8HLgSeEtm3tBmcZIkjUfTPbUzgcOB+zLzHuA44OzW\nqpIkaQKahlpfZt4xdCczvw1s3U5JkiRNTNNQuz8i9gIGASLiSOD+1qqSJGkCGp1TozrceB6wZ0Ss\nA34IHNlaVZIkTUDTUDs4M18REdsAczLzgTaLkiRpIpqG2vHA2Zn5UJvFSJI0GU1D7WcRcQXwPeA3\nQw9m5kdaqUqSpAloGmrXdtzuaaMQSZImq1GoZeaHO+9HRA+wWysVSZI0QU2/UeR44BPANh0P3wU8\np42iJEmaiKafU3s/sBfwZeDZwDupzq9JkrTFaBpq92bmXcDNwIsyczkQrVUlSdIENL1Q5KGIOIgq\n1A6LiO8DY35jf0TsCPwAOBjYCCyn+laSW4ElmblpIkVLkjSSUffUImLn+uZ7gNcD3wKeCqwG/n6M\nZecCn+OxjwAsA5Zm5gKqKygPnXjZkiQ90Vh7al8H9snM2yLinnrP6k0N2z6d6pv8T67v70v1kzUA\nK4BXAZeM1sD8+X309s5p2J3UHRwX0uaNFWqdn0k7EjijSaMRcQywJjMvjYihUOvJzMH69npg+7Ha\nWbt2Q5PupFlvYKC/8byOC3WD8YyJTmOF2mDH7fF86PodwGBELAL2Bs4HduyY3g+sG0d7kiSNqenV\nj/D4gBtVZh6QmQdm5kLgJuAoYEVELKxnWQysGkffkiSNaaw9tT0j4sf17Z07bvcAg5m5+zj6ej9w\nTkTMA+4ALh5fqZIkjW6sUHveZDuo99aGHDjZ9iRJ2pxRQy0z756uQiRJmqzxnFOTJGmLZqhJkoph\nqEmSimGoSZKKYahJkophqEmSimGoSZKKYahJkophqEmSimGoSZKKYahJkophqEmSimGoSZKKYahJ\nkophqEmSimGoSZKKYahJkophqEmSimGoSZKKYahJkophqEmSimGoSZKKYahJkophqEmSimGoSZKK\nYahJkophqEmSimGoSZKKYahJkophqEmSitHbRqMRMRc4F9gV2Br4GHA7sBwYBG4FlmTmpjb6lyR1\np7b21N4G3JeZC4DXAP8ALAOW1o/1AIe21LckqUu1FWpfAU6pb/cAG4F9gSvrx1YAi1rqW5LUpVo5\n/JiZDwJERD9wMbAUOD0zB+tZ1gPbj9XO/Pl99PbOaaNEadZyXEib10qoAUTELsAlwFmZeWFEfLJj\ncj+wbqw21q7d0FZ50hZlYKC/8byOC3WD8YyJTq0cfoyIpwGXAX+VmefWD98YEQvr24uBVW30LUnq\nXm3tqX0ImA+cEhFD59beB5wZEfOAO6gOS0qSNGV6BgcHx55rhqxZs37LLU6aQgMD/T1N53VcqBuM\nZ0x08sPXkqRiGGqSpGIYapKkYhhqkqRiGGqSpGIYapKkYhhqkqRitPY1WdNpxdWrZ7qEWWHx/nvM\ndAmS1Cr31CRJxShiT03S43n0ormpOoLhOm+uzaNG7qlJkophqEmSimGoSZKK4Tk1TYjnD5rzqlNp\n+rinJkkqhqEmSSqGoSZJKoahJkkqhqEmSSqGoSZJKoahJkkqhqEmSSqGoSZJKoahJkkqhqEmSSqG\noSZJKoahJkkqhqEmSSqGoSZJKoahJkkqhqEmSSqGoSZJKkbvdHYWEVsBZwF7AQ8D78rMH01nDZKk\nck33ntphwJMy8+XAScAZ09y/JKlg0x1qrwC+BZCZ1wIvnub+JUkF6xkcHJy2ziLiH4F/ycwV9f2f\nArtn5sZpK0KSVKzp3lN7AOjv7N9AkyRNlekOtauB1wJExMuAW6a5f0lSwab16kfgEuDgiLgG6AH+\ndJr7lyQVbFrPqUmS1CY/fC1JKoahJkkqhqEmSSrGdF8oMqtERC/wbWBr4HWZuXaK2v1lZj59KtrS\nyCLiGGCPzDxppmspiWNi9uqWMWGojW4nYLvM3HemC5G2EI4JbdEMtdGdDTw3Ir5A9aHxp9aPvzcz\nb4mIHwHXAM8DLge2B14KZGa+PSJeCCwD5gA7AMdl5jVDjUfEi4AzqT7ecB/wjsz89fQ8tdmj3sJ8\nPfB7wDOAvwMOBV4IfADYBXgjsA3wK+DwYcu/B3grMAh8KTPPnK7aC+SY2AI4JjbPc2qj+wvgduBe\n4PLMPAh4N/DZevquwFJgAfBeql8g+CPgFRHxZGBP4P2Z+Urgb3ni5/LOAZZk5kLg34ET23wys1x/\nZr6Waj0eRzVg3w28k+qNdVFm/hHVhtpLhhaKiBcAR1B97+gC4LCIiGmuvSSOiS2HY2IE7qk18yLg\njyPiiPr+U+r/78vMnwJExEOZeXt9+9fAk4B7gFMi4jdUW7UPDGv3+cBZ9etpLvDDVp/F7HZj/f86\n4I7MHIyItcA84BHgooh4EHgm1boc8kLgWVR7DQDzgecCOS1Vl8sxMfMcEyNwT62Z1cCn663HtwAX\n1I+P9cn1M4G/zsyjqb4SrGfY9ASOqts9EfjGVBVcoM2t63nAYZl5BPAeqtd053pO4DbgoHo9Lwdu\nbq/MruGYmHmOiRG4p9bMx4HPR8S7ge2AUxsudwHwlXrr6f9RnUPodBxwfn1F2SDVYQONz0bgoYi4\nur7/C6qLGQDIzP+IiMuBqyJia+A6qr0FTY5jYsvV1WPCr8mSJBXDw4+SpGIYapKkYhhqkqRiGGqS\npGIYapKkYnhJfxeKiDcDJ1P9/bcCzs/MT81sVdLMcUyUwz21LhMROwNnAK/KzL2AlwP/PSLeMLOV\nSTPDMVEW99S6zw5UX5nTR/WVRg9GxNHAbyPiJcCn62m/Av6s/v8W4J2ZeXlEXAr8W2aeNTPlS1PO\nMVEQP3zdhSLis8C7qL477rvAhcAdwPeB12fmTyPi1cAHM3NRRPwx1RfWngkckpmLZ6h0qRWOiXIY\nal2qPuTyKuDVVD9ZcRrVd+39qGO27TJz93r+z1L9VMUemfmLaS5Xap1jogwefuwyEfE6YNvM/DLw\nBeALEXEs1eD8cWbuXc83B3hafbsHCGAD1e9kOYBVDMdEWbxQpPtsAE6LiF3hvwbnC4BrgadExIJ6\nvndQHYKB6je0HqTaev3HiNhmWiuW2uWYKIiHH7tQfRL8gzz2G0uXUv1a7r5Uv6D7JKrfuToa2ET1\nS8YvzcyfRcQ/AFtl5l9Me+FSSxwT5TDUJEnF8PCjJKkYhpokqRiGmiSpGIaaJKkYhpokqRiGmiSp\nGIaaJKkY/z+DRnPKrZ4megAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127fe3550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = sns.FacetGrid(train_df, row='Embarked', col='Survived')\n",
    "grid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Passengers who paid higher fares survived more. \n",
    "#Port of embarkation shows correlates with survival. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting data :  Sex to Gender where female=1 and male=0.\n",
    "for dataset in combine:\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting data :  Sibsp and parch is converted to isAlone like a flag. if person is travelling alone isAlone =0 else 1\n",
    "for dataset in combine:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['SibSp'] > 1, 'IsAlone'] = 1\n",
    "    dataset.loc[dataset['Parch'] > 1, 'IsAlone'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#completing missing data : Fill missing values for age \n",
    "#For our dataset we note corelation among Age, Gender, and Pclass. \n",
    "guess_ages = np.zeros((2,3))\n",
    "print(guess_ages)\n",
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & \\\n",
    "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "\n",
    "           \n",
    "            age_guess = guess_df.median()\n",
    "\n",
    "          \n",
    "            guess_ages[i,j] = int( age_guess/0.2 + 0.2 ) * 0.2\n",
    "            \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n",
    "                    'Age'] = guess_ages[i,j]\n",
    "\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    \n",
    "    train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\n",
    "    \n",
    "    \n",
    "    for dataset in combine:    \n",
    "        dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "        dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "        dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "        dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "        dataset.loc[ dataset['Age'] > 64, 'Age']\n",
    "    \n",
    "    train_df = train_df.drop(['AgeBand'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Name', 'PassengerId','Embarked','Ticket','Cabin','Parch','SibSp','Fare'], axis=1)\n",
    "test_df = test_df.drop(['Embarked','Ticket','Cabin','Parch','SibSp','Fare'], axis=1)\n",
    "combine = [train_df,test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train_df.drop(\"Survived\", axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n",
    "X_test = test_df.drop(['Name', 'PassengerId'], axis=1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "LogisticRegression = LogisticRegression()\n",
    "LogisticRegression.fit(X_train, Y_train)\n",
    "Y_pred = LogisticRegression.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.680000000000007"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_log = round(LogisticRegression.score(X_train, Y_train) * 100, 2)\n",
    "accuracy_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "RandomForestClassifier = RandomForestClassifier(n_estimators=100)\n",
    "RandomForestClassifier.fit(X_train, Y_train)\n",
    "Y_pred = RandomForestClassifier.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.930000000000007"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_RandomForestClassifier = round(RandomForestClassifier.score(X_train, Y_train) * 100, 2)\n",
    "accuracy_RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "DecisionTreeClassifier = DecisionTreeClassifier()\n",
    "DecisionTreeClassifier.fit(X_train, Y_train)\n",
    "Y_pred = DecisionTreeClassifier.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.930000000000007"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_DecisionTreeClassifier = round(DecisionTreeClassifier.score(X_train, Y_train) * 100, 2)\n",
    "accuracy_DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "\n",
    "Perceptron = Perceptron()\n",
    "Perceptron.fit(X_train, Y_train)\n",
    "Y_pred = Perceptron.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.219999999999999"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_Perceptron = round(Perceptron.score(X_train, Y_train) * 100, 2)\n",
    "accuracy_Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.359999999999999"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_svc = round(svc.score(X_train, Y_train) * 100, 2)\n",
    "accuracy_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVC\n",
    "\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_train, Y_train)\n",
    "Y_pred = linear_svc.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.680000000000007"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\n",
    "accuracy_linear_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "SGDClassifier = SGDClassifier()\n",
    "SGDClassifier.fit(X_train, Y_train)\n",
    "Y_pred = SGDClassifier.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.680000000000007"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_SGDClassifier = round(SGDClassifier.score(X_train, Y_train) * 100, 2)\n",
    "accuracy_SGDClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNeighborsClassifier = KNeighborsClassifier(n_neighbors = 3)\n",
    "KNeighborsClassifier.fit(X_train, Y_train)\n",
    "Y_pred = KNeighborsClassifier.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.109999999999999"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_KNeighborsClassifier = round(KNeighborsClassifier.score(X_train, Y_train) * 100, 2)\n",
    "accuracy_KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "GaussianNB = GaussianNB()\n",
    "GaussianNB.fit(X_train, Y_train)\n",
    "Y_pred = GaussianNB.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.530000000000001"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_GaussianNB = round(GaussianNB.score(X_train, Y_train) * 100, 2)\n",
    "accuracy_GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xgboost\n",
    "xgboost_prediction = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(X_train, Y_train)\n",
    "Y_pred = xgboost_prediction.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.709999999999994"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_xgboost_prediction = round(xgboost_prediction.score(X_train, Y_train) * 100, 2)\n",
    "accuracy_xgboost_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#validating models using K-Fold\n",
    "\n",
    "\n",
    "def run_kfold(model):\n",
    "    print(\"\\n\")\n",
    "    print(str(model).split(\"(\")[0])\n",
    "    print(\"\\n\")\n",
    "    kf = KFold(891, n_folds=10)\n",
    "    outcomes = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf:\n",
    "        fold += 1\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        accuracy = round(model.score(X_train, Y_train) * 100, 2)\n",
    "        outcomes.append(accuracy)\n",
    "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy))     \n",
    "    mean_outcome = np.mean(outcomes)\n",
    "    print(\"Mean Accuracy: {0}\".format(mean_outcome)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LogisticRegression\n",
      "\n",
      "\n",
      "Fold 1 accuracy: 78.68\n",
      "Fold 2 accuracy: 78.68\n",
      "Fold 3 accuracy: 78.68\n",
      "Fold 4 accuracy: 78.68\n",
      "Fold 5 accuracy: 78.68\n",
      "Fold 6 accuracy: 78.68\n",
      "Fold 7 accuracy: 78.68\n",
      "Fold 8 accuracy: 78.68\n",
      "Fold 9 accuracy: 78.68\n",
      "Fold 10 accuracy: 78.68\n",
      "Mean Accuracy: 78.68000000000002\n",
      "\n",
      "\n",
      "RandomForestClassifier\n",
      "\n",
      "\n",
      "Fold 1 accuracy: 81.93\n",
      "Fold 2 accuracy: 81.93\n",
      "Fold 3 accuracy: 81.93\n",
      "Fold 4 accuracy: 81.93\n",
      "Fold 5 accuracy: 81.93\n",
      "Fold 6 accuracy: 81.93\n",
      "Fold 7 accuracy: 81.93\n",
      "Fold 8 accuracy: 81.82\n",
      "Fold 9 accuracy: 81.93\n",
      "Fold 10 accuracy: 81.93\n",
      "Mean Accuracy: 81.91900000000001\n",
      "\n",
      "\n",
      "DecisionTreeClassifier\n",
      "\n",
      "\n",
      "Fold 1 accuracy: 81.93\n",
      "Fold 2 accuracy: 81.93\n",
      "Fold 3 accuracy: 81.93\n",
      "Fold 4 accuracy: 81.93\n",
      "Fold 5 accuracy: 81.93\n",
      "Fold 6 accuracy: 81.93\n",
      "Fold 7 accuracy: 81.93\n",
      "Fold 8 accuracy: 81.93\n",
      "Fold 9 accuracy: 81.93\n",
      "Fold 10 accuracy: 81.93\n",
      "Mean Accuracy: 81.93000000000002\n",
      "\n",
      "\n",
      "Perceptron\n",
      "\n",
      "\n",
      "Fold 1 accuracy: 77.22\n",
      "Fold 2 accuracy: 77.22\n",
      "Fold 3 accuracy: 77.22\n",
      "Fold 4 accuracy: 77.22\n",
      "Fold 5 accuracy: 77.22\n",
      "Fold 6 accuracy: 77.22\n",
      "Fold 7 accuracy: 77.22\n",
      "Fold 8 accuracy: 77.22\n",
      "Fold 9 accuracy: 77.22\n",
      "Fold 10 accuracy: 77.22\n",
      "Mean Accuracy: 77.22\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "\n",
      "\n",
      "Fold 1 accuracy: 81.71\n",
      "Fold 2 accuracy: 81.71\n",
      "Fold 3 accuracy: 81.71\n",
      "Fold 4 accuracy: 81.71\n",
      "Fold 5 accuracy: 81.71\n",
      "Fold 6 accuracy: 81.71\n",
      "Fold 7 accuracy: 81.71\n",
      "Fold 8 accuracy: 81.71\n",
      "Fold 9 accuracy: 81.71\n",
      "Fold 10 accuracy: 81.71\n",
      "Mean Accuracy: 81.71000000000001\n",
      "\n",
      "\n",
      "SVC\n",
      "\n",
      "\n",
      "Fold 1 accuracy: 80.36\n",
      "Fold 2 accuracy: 80.36\n",
      "Fold 3 accuracy: 80.36\n",
      "Fold 4 accuracy: 80.36\n",
      "Fold 5 accuracy: 80.36\n",
      "Fold 6 accuracy: 80.36\n",
      "Fold 7 accuracy: 80.36\n",
      "Fold 8 accuracy: 80.36\n",
      "Fold 9 accuracy: 80.36\n",
      "Fold 10 accuracy: 80.36\n",
      "Mean Accuracy: 80.36\n",
      "\n",
      "\n",
      "KNeighborsClassifier\n",
      "\n",
      "\n",
      "Fold 1 accuracy: 78.11\n",
      "Fold 2 accuracy: 78.11\n",
      "Fold 3 accuracy: 78.11\n",
      "Fold 4 accuracy: 78.11\n",
      "Fold 5 accuracy: 78.11\n",
      "Fold 6 accuracy: 78.11\n",
      "Fold 7 accuracy: 78.11\n",
      "Fold 8 accuracy: 78.11\n",
      "Fold 9 accuracy: 78.11\n",
      "Fold 10 accuracy: 78.11\n",
      "Mean Accuracy: 78.11\n",
      "\n",
      "\n",
      "LinearSVC\n",
      "\n",
      "\n",
      "Fold 1 accuracy: 78.68\n",
      "Fold 2 accuracy: 78.68\n",
      "Fold 3 accuracy: 78.68\n",
      "Fold 4 accuracy: 78.68\n",
      "Fold 5 accuracy: 78.68\n",
      "Fold 6 accuracy: 78.68\n",
      "Fold 7 accuracy: 78.68\n",
      "Fold 8 accuracy: 78.68\n",
      "Fold 9 accuracy: 78.68\n",
      "Fold 10 accuracy: 78.68\n",
      "Mean Accuracy: 78.68000000000002\n",
      "\n",
      "\n",
      "GaussianNB\n",
      "\n",
      "\n",
      "Fold 1 accuracy: 75.53\n",
      "Fold 2 accuracy: 75.53\n",
      "Fold 3 accuracy: 75.53\n",
      "Fold 4 accuracy: 75.53\n",
      "Fold 5 accuracy: 75.53\n",
      "Fold 6 accuracy: 75.53\n",
      "Fold 7 accuracy: 75.53\n",
      "Fold 8 accuracy: 75.53\n",
      "Fold 9 accuracy: 75.53\n",
      "Fold 10 accuracy: 75.53\n",
      "Mean Accuracy: 75.53\n",
      "\n",
      "\n",
      "SGDClassifier\n",
      "\n",
      "\n",
      "Fold 1 accuracy: 64.09\n",
      "Fold 2 accuracy: 77.44\n",
      "Fold 3 accuracy: 67.34\n",
      "Fold 4 accuracy: 73.85\n",
      "Fold 5 accuracy: 70.26\n",
      "Fold 6 accuracy: 61.39\n",
      "Fold 7 accuracy: 69.81\n",
      "Fold 8 accuracy: 65.43\n",
      "Fold 9 accuracy: 71.94\n",
      "Fold 10 accuracy: 79.12\n",
      "Mean Accuracy: 70.067\n"
     ]
    }
   ],
   "source": [
    "run_kfold(LogisticRegression);\n",
    "run_kfold(RandomForestClassifier);\n",
    "run_kfold(DecisionTreeClassifier);\n",
    "run_kfold(Perceptron);\n",
    "run_kfold(xgboost_prediction);\n",
    "run_kfold(svc);\n",
    "run_kfold(KNeighborsClassifier);\n",
    "run_kfold(linear_svc);\n",
    "run_kfold(GaussianNB);\n",
    "run_kfold(SGDClassifier);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#DecisionTreeClassifier and RandomForestClassifier have highest accuracy i.e 81.93000000000002. I will use RandomForestClassifier to make my submission.\n",
    "Y_pred = RandomForestClassifier.predict(X_test)\n",
    "Y_pred\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#deep learning \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 1s 999us/step - loss: 0.6954 - acc: 0.5576 - val_loss: 0.6891 - val_acc: 0.6145\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 224us/step - loss: 0.6856 - acc: 0.6166 - val_loss: 0.6801 - val_acc: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 219us/step - loss: 0.6755 - acc: 0.6166 - val_loss: 0.6693 - val_acc: 0.6145\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 232us/step - loss: 0.6639 - acc: 0.6166 - val_loss: 0.6578 - val_acc: 0.6145\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 236us/step - loss: 0.6514 - acc: 0.6166 - val_loss: 0.6446 - val_acc: 0.6145\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 234us/step - loss: 0.6371 - acc: 0.6166 - val_loss: 0.6288 - val_acc: 0.6145\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 203us/step - loss: 0.6177 - acc: 0.6348 - val_loss: 0.6047 - val_acc: 0.7430\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 231us/step - loss: 0.5901 - acc: 0.7654 - val_loss: 0.5754 - val_acc: 0.7877\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 253us/step - loss: 0.5586 - acc: 0.7865 - val_loss: 0.5468 - val_acc: 0.7877\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 209us/step - loss: 0.5342 - acc: 0.7865 - val_loss: 0.5276 - val_acc: 0.7877\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 241us/step - loss: 0.5191 - acc: 0.7865 - val_loss: 0.5152 - val_acc: 0.7877\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 245us/step - loss: 0.5096 - acc: 0.7865 - val_loss: 0.5013 - val_acc: 0.7877\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 210us/step - loss: 0.4995 - acc: 0.7865 - val_loss: 0.4906 - val_acc: 0.7877\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 213us/step - loss: 0.4923 - acc: 0.7865 - val_loss: 0.4814 - val_acc: 0.7877\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 206us/step - loss: 0.4873 - acc: 0.7865 - val_loss: 0.4710 - val_acc: 0.7877\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 211us/step - loss: 0.4830 - acc: 0.7907 - val_loss: 0.4653 - val_acc: 0.7821\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 225us/step - loss: 0.4773 - acc: 0.8006 - val_loss: 0.4626 - val_acc: 0.7933\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 215us/step - loss: 0.4747 - acc: 0.8062 - val_loss: 0.4586 - val_acc: 0.7933\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 226us/step - loss: 0.4725 - acc: 0.8062 - val_loss: 0.4582 - val_acc: 0.7933\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 271us/step - loss: 0.4711 - acc: 0.8062 - val_loss: 0.4567 - val_acc: 0.7933\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 220us/step - loss: 0.4702 - acc: 0.8062 - val_loss: 0.4555 - val_acc: 0.7933\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 206us/step - loss: 0.4696 - acc: 0.8062 - val_loss: 0.4537 - val_acc: 0.7933\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 211us/step - loss: 0.4698 - acc: 0.8062 - val_loss: 0.4519 - val_acc: 0.7933\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 214us/step - loss: 0.4687 - acc: 0.8062 - val_loss: 0.4513 - val_acc: 0.7933\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 220us/step - loss: 0.4687 - acc: 0.8062 - val_loss: 0.4491 - val_acc: 0.7933\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 218us/step - loss: 0.4675 - acc: 0.8062 - val_loss: 0.4486 - val_acc: 0.7933\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 226us/step - loss: 0.4674 - acc: 0.8062 - val_loss: 0.4477 - val_acc: 0.7933\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 202us/step - loss: 0.4669 - acc: 0.8062 - val_loss: 0.4473 - val_acc: 0.7933\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 205us/step - loss: 0.4662 - acc: 0.8062 - val_loss: 0.4469 - val_acc: 0.7933\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 204us/step - loss: 0.4658 - acc: 0.8062 - val_loss: 0.4463 - val_acc: 0.7933\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 205us/step - loss: 0.4656 - acc: 0.8062 - val_loss: 0.4460 - val_acc: 0.7933\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 222us/step - loss: 0.4654 - acc: 0.8062 - val_loss: 0.4450 - val_acc: 0.7933\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 231us/step - loss: 0.4647 - acc: 0.8062 - val_loss: 0.4441 - val_acc: 0.7933\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 220us/step - loss: 0.4650 - acc: 0.8062 - val_loss: 0.4432 - val_acc: 0.7933\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 223us/step - loss: 0.4643 - acc: 0.8062 - val_loss: 0.4426 - val_acc: 0.7933\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 220us/step - loss: 0.4642 - acc: 0.8062 - val_loss: 0.4418 - val_acc: 0.7933\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 236us/step - loss: 0.4640 - acc: 0.8062 - val_loss: 0.4413 - val_acc: 0.7933\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 211us/step - loss: 0.4634 - acc: 0.8062 - val_loss: 0.4406 - val_acc: 0.7933\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 215us/step - loss: 0.4638 - acc: 0.8062 - val_loss: 0.4399 - val_acc: 0.7933\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 211us/step - loss: 0.4630 - acc: 0.8062 - val_loss: 0.4385 - val_acc: 0.7933\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 219us/step - loss: 0.4624 - acc: 0.8062 - val_loss: 0.4384 - val_acc: 0.7933\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 206us/step - loss: 0.4624 - acc: 0.8062 - val_loss: 0.4374 - val_acc: 0.7933\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 228us/step - loss: 0.4613 - acc: 0.8062 - val_loss: 0.4362 - val_acc: 0.7933\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 266us/step - loss: 0.4610 - acc: 0.8062 - val_loss: 0.4356 - val_acc: 0.7933\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 209us/step - loss: 0.4609 - acc: 0.8062 - val_loss: 0.4339 - val_acc: 0.7933\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 202us/step - loss: 0.4602 - acc: 0.8062 - val_loss: 0.4332 - val_acc: 0.7933\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 215us/step - loss: 0.4598 - acc: 0.8062 - val_loss: 0.4323 - val_acc: 0.7933\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 214us/step - loss: 0.4600 - acc: 0.8062 - val_loss: 0.4319 - val_acc: 0.7933\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 222us/step - loss: 0.4590 - acc: 0.8062 - val_loss: 0.4309 - val_acc: 0.7933\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 229us/step - loss: 0.4588 - acc: 0.8062 - val_loss: 0.4311 - val_acc: 0.7933\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 238us/step - loss: 0.4584 - acc: 0.8062 - val_loss: 0.4302 - val_acc: 0.7933\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 223us/step - loss: 0.4580 - acc: 0.8062 - val_loss: 0.4290 - val_acc: 0.7933\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 193us/step - loss: 0.4578 - acc: 0.8062 - val_loss: 0.4284 - val_acc: 0.7933\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 203us/step - loss: 0.4574 - acc: 0.8062 - val_loss: 0.4273 - val_acc: 0.7933\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 208us/step - loss: 0.4574 - acc: 0.8062 - val_loss: 0.4269 - val_acc: 0.7933\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 216us/step - loss: 0.4568 - acc: 0.8062 - val_loss: 0.4263 - val_acc: 0.7933\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 231us/step - loss: 0.4566 - acc: 0.8062 - val_loss: 0.4259 - val_acc: 0.7933\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 224us/step - loss: 0.4563 - acc: 0.8062 - val_loss: 0.4246 - val_acc: 0.7933\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 226us/step - loss: 0.4563 - acc: 0.8062 - val_loss: 0.4242 - val_acc: 0.7933\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 220us/step - loss: 0.4557 - acc: 0.8062 - val_loss: 0.4230 - val_acc: 0.7933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 238us/step - loss: 0.4555 - acc: 0.8062 - val_loss: 0.4232 - val_acc: 0.7933\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 234us/step - loss: 0.4548 - acc: 0.8062 - val_loss: 0.4224 - val_acc: 0.7933\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 240us/step - loss: 0.4549 - acc: 0.8062 - val_loss: 0.4218 - val_acc: 0.7933\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 211us/step - loss: 0.4544 - acc: 0.8062 - val_loss: 0.4217 - val_acc: 0.7933\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 203us/step - loss: 0.4551 - acc: 0.8062 - val_loss: 0.4205 - val_acc: 0.7933\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 230us/step - loss: 0.4538 - acc: 0.8062 - val_loss: 0.4198 - val_acc: 0.7933\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 240us/step - loss: 0.4537 - acc: 0.8062 - val_loss: 0.4187 - val_acc: 0.7933\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 221us/step - loss: 0.4537 - acc: 0.8062 - val_loss: 0.4189 - val_acc: 0.7933\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 213us/step - loss: 0.4530 - acc: 0.8062 - val_loss: 0.4181 - val_acc: 0.7933\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 216us/step - loss: 0.4532 - acc: 0.8062 - val_loss: 0.4173 - val_acc: 0.7933\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 214us/step - loss: 0.4527 - acc: 0.8062 - val_loss: 0.4168 - val_acc: 0.7933\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 244us/step - loss: 0.4525 - acc: 0.8062 - val_loss: 0.4164 - val_acc: 0.7933\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 252us/step - loss: 0.4520 - acc: 0.8062 - val_loss: 0.4159 - val_acc: 0.7933\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 262us/step - loss: 0.4520 - acc: 0.8062 - val_loss: 0.4156 - val_acc: 0.7933\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 232us/step - loss: 0.4519 - acc: 0.8062 - val_loss: 0.4150 - val_acc: 0.7933\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 235us/step - loss: 0.4518 - acc: 0.8062 - val_loss: 0.4147 - val_acc: 0.7933\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 215us/step - loss: 0.4521 - acc: 0.8062 - val_loss: 0.4141 - val_acc: 0.7933\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 228us/step - loss: 0.4514 - acc: 0.8062 - val_loss: 0.4129 - val_acc: 0.7933\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 228us/step - loss: 0.4513 - acc: 0.8062 - val_loss: 0.4116 - val_acc: 0.7933\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 250us/step - loss: 0.4507 - acc: 0.8062 - val_loss: 0.4113 - val_acc: 0.7933\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 237us/step - loss: 0.4505 - acc: 0.8062 - val_loss: 0.4109 - val_acc: 0.7933\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 230us/step - loss: 0.4503 - acc: 0.8062 - val_loss: 0.4098 - val_acc: 0.7933\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 222us/step - loss: 0.4501 - acc: 0.8062 - val_loss: 0.4087 - val_acc: 0.7933\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 244us/step - loss: 0.4500 - acc: 0.8062 - val_loss: 0.4093 - val_acc: 0.7933\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 226us/step - loss: 0.4502 - acc: 0.8062 - val_loss: 0.4093 - val_acc: 0.7933\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 219us/step - loss: 0.4504 - acc: 0.8062 - val_loss: 0.4078 - val_acc: 0.7877\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 227us/step - loss: 0.4497 - acc: 0.8062 - val_loss: 0.4077 - val_acc: 0.7877\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 236us/step - loss: 0.4498 - acc: 0.8062 - val_loss: 0.4086 - val_acc: 0.7933\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 228us/step - loss: 0.4499 - acc: 0.8062 - val_loss: 0.4089 - val_acc: 0.7877\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 231us/step - loss: 0.4496 - acc: 0.8062 - val_loss: 0.4089 - val_acc: 0.7877\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 211us/step - loss: 0.4494 - acc: 0.8062 - val_loss: 0.4078 - val_acc: 0.7877\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 217us/step - loss: 0.4501 - acc: 0.8062 - val_loss: 0.4087 - val_acc: 0.7877\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 226us/step - loss: 0.4502 - acc: 0.8076 - val_loss: 0.4076 - val_acc: 0.7877\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 235us/step - loss: 0.4492 - acc: 0.8062 - val_loss: 0.4083 - val_acc: 0.7877\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 243us/step - loss: 0.4492 - acc: 0.8062 - val_loss: 0.4083 - val_acc: 0.7877\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 237us/step - loss: 0.4495 - acc: 0.8062 - val_loss: 0.4087 - val_acc: 0.7877\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 205us/step - loss: 0.4500 - acc: 0.8090 - val_loss: 0.4095 - val_acc: 0.7877\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 208us/step - loss: 0.4496 - acc: 0.8062 - val_loss: 0.4084 - val_acc: 0.7877\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 242us/step - loss: 0.4493 - acc: 0.8062 - val_loss: 0.4081 - val_acc: 0.7877\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 225us/step - loss: 0.4491 - acc: 0.8090 - val_loss: 0.4079 - val_acc: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x126f89da0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier = Sequential()\n",
    "# Using relu for hidden layers and sigmoid for output layer \n",
    "# Adding the input and first hidden layer\n",
    "#units = (4 +1) /2\n",
    "classifier.add(Dense(units = 3 , use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', activation='relu' , input_dim =4))\n",
    "\n",
    "# Adding 2 hidden layers\n",
    "classifier.add(Dense(units = 3 , use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', activation='relu'))\n",
    "classifier.add(Dense(units = 3 , use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', activation='relu'))\n",
    "#classifier.add(LSTM(100))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1 , use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', activation='sigmoid'))\n",
    "\n",
    "\n",
    "classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "classifier.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, batch_size=10)\n",
    "#classifier.fit(X_train, Y_train, batch_size = 10, epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = classifier.predict(X_test) \n",
    "# We need to change y_pred from probabilities to boolean values in order for the confusion matrix to work\n",
    "Y_pred = (Y_pred > 0.5) #Will return True if y_pred>0.5(threshold is 50%) and false if less\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[97 13]\n",
      " [25 44]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
